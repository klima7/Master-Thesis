\chapter{Podsumowanie}

W ramach realizacji ważnego i aktualnego tematu, jakim jest tłumaczenie zapytań z języka polskiego na SQL, najpierw dokonano przeglądu istniejących jedynie dla innych języków zbiorów danych. Przeanalizowano różnice w podejściach ich autorów i wybrano optymalne dla przypadku języka polskiego. Następnie poświęcono dużo uwagi na przygotowanie odpowiednich zbiorów i z ich wykorzystaniem przetestowano wybrane rozwiązania. Okazało się, że najlepsze rezultaty w fazie eksperymentów osiągnęły znacznie różniące się od siebie modele \code{RESDSQL} oraz \code{C3}, z których pierwszy został poddany powtórnemu, rozszerzonemu treningowi. Modele te zostały zintegrowane z aplikacją internetową umożliwiającą interaktywne generowanie i wykonywanie zapytań SQL. Podczas manualnej oceny użytkownicy dobrze ocenili działanie systemu, doceniając jego praktyczne zastosowanie. Okazało się jednak, że minimalna znajomość języka SQL wciąż jest potrzebna w celu weryfikacji produkowanych zapytań.

Podsumowując, w ramach pracy zrealizowano wszystkie założone cele, których głównymi punktami było przygotowanie polskich zbiorów dla problemu \code{Text-to-SQL} i przeprowadzenie z ich wykorzystaniem eksperymentów. Przetestowanie czterech różnych rozwiązań pozwoliło zapoznać się ze sposobem ewolucji wykorzystywanych do tego celu modeli. W trakcie eksperymentów potwierdzono zaobserwowane już wcześniej zjawisko polegające na tym, że modele osiągają lepsze rezultaty, gdy uczone są na dwujęzycznych zbiorach. Pokazano także, że rozwiązania bazujące na zamkniętych modelach językowych, na przykład udostępnianych przez \code{OpenAI}, mogą osiągać bardzo dobre wyniki, lecz ze względu na swoją specyfikę nie wszędzie się sprawdzą.

W celu ewentualnej kontynuacji niniejszego tematu zdecydowanie warto dokonać ręcznej weryfikacji i poprawek stworzonych z wykorzystaniem tłumaczenia maszynowego zbiorów. Obecność w nich wielu niedociągnięć jest bowiem wiadoma, a ich usunięcie pozwoli trenować wyższej jakości modele. Przypuszcza się, że poprawę skuteczności można uzyskać również poprzez naukę na połączeniu wszystkich istniejących tłumaczeń zbioru \code{Spider}, zamiast jedynie polskiego z angielskim, co testowali już autorzy \code{MultiSpider} \mycite{Dou2022}. Aby zmniejszyć wymagania pamięciowe modelu \code{RESDSQL} można spróbować dokonać kwantyzacji 8-bitowej \mycite{noune20228bit,perez2023training}. Jeszcze innym pomysłem jest przetestowanie dla polskiego przypadku rozwiązań z aktualnego szczytu rankingu \code{Spider}, które bazują na udostępnianym przez \code{OpenAI} modelu \code{GPT-4}, co w tej pracy pominięto ze względu na koszty.