\chapter{Finalne rozwiązanie}
Wszystkie przeprowadzone we wcześniejszej części testy modeli sprowadzały się wyłącznie do oceny automatycznej. Wyciągnięto z niej wniosek, że bardzo dobrze spisuje się model \code{RESDSQL}, a \code{C3} również jest godny uwagi. Z tego względu w niniejszym rozdziale postanowiono dokonać ponownego treningu \code{RESDSQL}, lecz z wykorzystaniem większej wersji modelu \code{T5} oraz większej ilości danych. Tak jak wcześniej dokonano automatycznej oceny, lecz poza tym zaimplementowano interfejs graficzny, pozwalający na praktyczne wykorzystanie oraz manualną ocenę dwóch wybranych modeli. Stworzoną aplikację przedstawiono kilku osobom w celu przetestowania i wyrażenia swojej opinii. Te skrótowo opisane działania zostaną w kolejnych sekcjach rozwinięte.

\section{Ponowny trening RESDSQL}
Jako że wyniki modelu \code{RESDSQL} okazały się najlepsze spośród wszystkich klasycznych, trenowalnych rozwiązań, postanowiono dokonać jego nauki ponownie, lecz z wykorzystaniem rozszerzonego zbioru oraz większego wariantu modelu \code{T5}, licząc na jeszcze lepsze rezultaty.

Wcześniej do treningu wykorzystano jedynie warianty zbioru \code{Spider}, ponieważ pozwoliło to skrócić czas treningu oraz wykonywać rzetelne porównania z modelami tworzonymi przez innych badaczy, którzy również dokonywali treningu wyłącznie na tym zbiorze. Teraz poza zbiorem \code{Spider} do danych treningowych postanowiono włączyć \code{Spider-Syn}, \code{SParC} oraz \code{CoSQL} w wariantach z polskimi i angielskimi schematami baz danych, a także ich angielskie pierwowzory. Zbiór \code{Spider-DK} pominięto, ponieważ zawiera on jedynie przykłady testowe. Posługując się wcześniej wprowadzonymi nazwami, można powiedzieć inaczej, że do zbioru treningowego wybrano \code{Mix-Spider}, \code{Mix-Spidersyn}, \code{Mix-Sparc} oraz \code{Mix-Cosql}. W ten sposób ilość danych treningowych została zwiększona prawie dwukrotnie.

Wariant modelu \code{T5} postanowiono zmienić z wcześniej wykorzystanego \code{mt5-base} na \code{mt5-large}, który zawiera dwukrotnie większą liczbę parametrów. Powoduje ona, że model jest w stanie pomieścić znacznie większą wiedzę. W fazie eksperymentów nie skorzystano z tego, ponieważ nie dysponowano kartą graficzną o odpowiednio dużej ilości pamięci \code{VRAM}. \textbf{Stało się to możliwe dzięki uprzejmości p. Grzegorza Warzechy z firmy TaskPilot, który udostępnił odpowiednie zasoby sprzętowe} i do treningu wykorzystano potężną kartę \code{Nvidia RTX 4090}, dysponującą 24 GB pamięci \code{VRAM}.

Na rozwiązanie \code{RESDSQL} składają się dwa modele. Pierwszego, oceniającego istotność tabel i kolumn, nie uczono ponownie, lecz wykorzystano ten wytrenowany wcześniej. Zamiana rozmiaru modelu językowego \code{T5} i ponowny trening tyczy się jedynie drugiego etapu, w którym następuje ostateczne generowanie zapytań SQL. Naukę kontynuowano przez 14 godzin, a wyniki kompletnego modelu przedstawiono w tabeli \ref{tab:resdsql-final-difficulty}. Porównanie wyników osiąganych przez ten finalny model z modelem eksperymentalnym przedstawiono natomiast na rysunku \ref{fig:final-resdsql-radar}.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|r|r|r|r|r|}
        \hline
        \thead{Zbiór} & \thead{Easy} & \thead{Medium} & \thead{Hard} & \thead{Extra Hard} & \thead{Razem} \\
        \hline
        Pol-Spider & 
        \threevals{85,5}{76,8}{87,7} &
        \threevals{73,4}{66,6}{78,8} &
        \threevals{52,6}{48,3}{66,7} &
        \threevals{41,6}{38,0}{57,2} &
        \threevals{67,7}{61,4}{75,4} \\
        
        Pol-Spider-PL &
        \threevals{86,7}{78,6}{87,9} &
        \threevals{74,7}{67,9}{79,4} &
        \threevals{54,0}{48,9}{67,8} &
        \threevals{41,0}{36,7}{56,6} &
        \threevals{68,7}{62,3}{75,8} \\
        
        Pol-Spider-EN &
        \threevals{84,3}{75,0}{87,5} &
        \threevals{72,2}{65,2}{78,3} &
        \threevals{51,1}{47,7}{65,5} &
        \threevals{42,2}{39,2}{57,8} &
        \threevals{66,7}{60,4}{75,0} \\
        
        En-Spider &
        \threevals{86,7}{83,5}{88,3} &
        \threevals{76,9}{73,8}{79,6} &
        \threevals{59,2}{56,9}{65,5} &
        \threevals{47,6}{47,0}{53,0} &
        \threevals{71,6}{69,0}{75,0} \\
        
        \hline
        
        Pol-Spidersyn &
        \threevals{72,2}{64,0}{80,4} &
        \threevals{64,3}{60,3}{75,4} &
        \threevals{46,0}{45,6}{60,7} &
        \threevals{38,0}{35,5}{51,7} &
        \threevals{58,7}{54,7}{70,2} \\
        
        Pol-Spiderdk &
        \threevals{63,2}{58,2}{67,7} &
        \threevals{49,2}{44,1}{56,1} &
        \threevals{33,1}{33,1}{48,6} &
        \threevals{22,9}{21,4}{35,7} &
        \threevals{44,7}{41,0}{53,5} \\
        
        Pol-Sparc &
        \threevals{77,5}{72,1}{82,7} &
        \threevals{50,0}{44,2}{66,0} &
        \threevals{20,0}{20,0}{50,0} &
        \threevals{43,8}{43,8}{50,0} &
        \threevals{66,7}{61,5}{76,0} \\
        
        Pol-Cosql &
        \threevals{73,8}{67,9}{80,0} &
        \threevals{61,0}{54,2}{68,6} &
        \threevals{27,9}{27,9}{52,9} &
        \threevals{29,4}{26,5}{50,0} &
        \threevals{60,4}{55,4}{70,9} \\
        
        \hline
    \end{tabular}
    \lcaption{Wyniki finalnego modelu \code{RESDSQL} na poszczególnych zbiorach}{Wartości w każdej komórce posiadają format \mbox{EM Without Values / EM / EX} i zostały wyrażone w procentach.}
    \label{tab:resdsql-final-difficulty}
\end{table}

\begin{figure}[H]
  \centering
  \includesvg[width=0.8\linewidth]{images/final_resdsql_radar}
  \lcaption{Porównanie wyników eksperymentalnego i finalnego modelu \code{RESDSQL}}{Metryki wyrażono w procentach.}
  \label{fig:final-resdsql-radar}
\end{figure}


Wyniki testów pokazują, że zwiększenie rozmiaru modelu \code{T5}, wraz z rozszerzeniem zbioru treningowego, pozwoliło wyraźnie podnieść wyniki wszystkich metryk w porównaniu do wcześniej trenowanej wersji. W przypadku każdego ze zbiorów testowych nastąpiło zwiększenie wartości metryki \code{EM} o przynajmniej 8 punktów procentowych. Wartość metryki \code{EX} również wzrosła, co sprawiło, że ta wersja modelu \code{RESDSQL} dorównuje pod tym kątem prawie modelowi \code{C3}.

\section{Aplikacja webowa}
W celu umożliwienia praktycznego wykorzystania oraz manualnej weryfikacji modeli \code{RESDSQL} oraz \code{C3} opracowany został interfejs graficzny w postaci aplikacji webowej. W szczególności duże wyzwanie stanowiło połączenie go z ze wspomnianymi modelami, ponieważ zostały stworzone do wykonywania predykcji na określonych zbiorach w sposób wsadowy. W tym przypadku musiały być jednak wykonywane dla pojedynczych pytań oraz dowolnych baz danych.

\subsection{Interfejs graficzny}
Interfejs graficzny, którego wygląd przedstawiono na rysunkach w dodatku \ref{chapter:gui}, został stworzony z wykorzystaniem biblioteki \code{streamlit}. Jak opisano w rozdziale o narzędziach, jej zaletą jest niebywała prostota, lecz wiąże się ona z pewnym brakiem elastyczności -- wpływanie na wygląd poszczególnych komponentów oraz interakcje pomiędzy nimi jest bardzo ograniczone. Przygotowana aplikacja wydaje się dość skomplikowana jak na możliwości tej biblioteki, lecz po dokładnym przemyśleniu struktury i szczegółowym zapoznaniem z dokumentacją, udało się ją zrealizować. Na aplikację składają się trzy zakładki: pierwsza pozwala na wybór bazy danych, druga na podanie naturalnych odpowiedników dla nazw tabel i kolumn, a trzecia na generowanie zapytań SQL.

\textbf{Pierwsza zakładka} umożliwia wybór bazy danych poprzez załadowanie jej w formacie \code{sqlite}, wybranie jednej z przygotowanych baz przykładowych lub wprowadzenie skryptu SQL, który ją tworzy. Sześć przykładowych baz wybrano z części testowej zbioru \code{Spider}, lecz dodatkowo dokonano tłumaczenia ich zawartości. Po dokonaniu decyzji ukazuje się diagram wybranej bazy, do zaimplementowania którego wykorzystano bibliotekę języka Python o nazwie \code{eralchemy}\furl{https://pypi.org/project/ERAlchemy}. Pozwala ona w łatwy sposób tworzyć diagramy relacji encji (ang. entity relation diagram). Dzięki temu możliwe jest powierzchowne zapoznanie się ze strukturą bazy i uświadomienie pytań, które można podawać do obsługującego ją interfejsu tekstowego.

\textbf{Druga zakładka} pozwala na podanie naturalnych odpowiedników dla nazw tabel i kolumn. Jej obecność jest wymuszona przez strukturę zbioru \code{Spider}, który zawiera taką informację oraz fakt, że rozwiązania \code{RESDSQL} oraz \code{C3} z niej korzystają. Jest to pewnego rodzaju informacja dodatkowa, której podawanie może być irytujące, szczególnie w przypadku dużych baz danych. Aby to usprawnić, opracowano prosty algorytm, który wstępnie proponuje nazwy naturalne poprzez rozbicie identyfikatorów tabel i kolumn na poszczególne słowa. W dużej mierze ogranicza to działania użytkownika do ich weryfikacji.

\textbf{Trzecia zakładka} umożliwia zadawanie pytań do określonej wcześniej bazy danych. Ma to postać chatu, w którym naprzemiennie użytkownik podaje swoje żądania oraz model wysyła przewidziane zapytania SQL. Forma ta może być nieco myląca, ponieważ sugeruje, że wykorzystywane modele działają w sposób kontekstowy, czyli biorą pod uwagę wcześniejszą historię wiadomości, podczas gdy tak nie jest. Jest ona jednak wygodna, gdyż większość użytkowników jest z nią zaznajomiona. Generowane zapytania są natychmiastowo wykonywane i interaktywne tabele z odczytanymi rekordami są bezpośrednio pod nimi zamieszczane, co jest bardzo ważne pod kątem praktycznego wykorzystania. Aktywny w danej chwili model można zmieniać za pomocą listy rozwijanej. Jeżeli wybrany został \code{C3}, to konieczny jest jednak dostęp do klucza API \code{OpenAI}, który można wprowadzić w odpowiednim polu tekstowym w interfejsie. Przewidziano również możliwość uruchomienia całej aplikacji z danym kluczem, a wówczas podawanie go przez poszczególnych użytkowników nie jest konieczne. Dostęp do interfejsu chroniony jest wówczas hasłem, by przeciwdziałać naliczaniu kosztów przez nieuprawnione osoby.

\subsection{Połączenie interfejsu z modelami}
Dość kłopotliwe okazało się połączenie stworzonego interfejsu z modelami, w szczególności z \code{RESDSQL}. W przypadku obu rozwiązań istniejący kod nie pozwala bowiem na proste generowanie zapytań do dowolnych baz danych. Wymagają, aby przykłady testowe były dostarczane w formacie wykorzystywanym przez zbiór \code{Spider}. Z tego powodu posiadając wybraną przez użytkownika bazę oraz naturalne odpowiedniki nazw tabel i kolumn, konieczne okazało się każdorazowe generowanie tymczasowego, jednoelementowego zbioru danych, co wymagało dodatkowego wysiłku.

Innego rodzaju problemem było generowanie przez \code{RESDSQL} zapytań w sposób, który można nazwać wsadowym. Odbywa się ono bowiem w dwóch etapach, z których każdy korzysta z osobnej sieci neuronowej. Istniejący kod działa w ten sposób, że ładuje do pamięci model pierwszy i przepuszcza przez niego wszystkie dane, a następnie zastępuje go drugim i podaje do niego wszystkie wyniki pośrednie. Sprawdza się to w przypadku generowania dużej liczby zapytań SQL jednocześnie, lecz niekoniecznie dla serii pojedynczych zapytań, tak jak w rozpatrywanym przypadku. Okazuję się wówczas, że większość czasu poświęcana jest naprzemiennemu ładowaniu sieci neuronowych do pamięci zamiast rzeczywistym obliczeniom. Z tego powodu zmodyfikowano kod w taki sposób, aby w pamięci znajdywały się przez cały czas obie sieci. Oznacza to oczywiście wykorzystanie znacznie większej ilości pamięci, czemu postanowiono przeciwdziałać poprzez załadowanie parametrów modeli z wykorzystaniem precyzji 16-bitowej zamiast oryginalnie 32-bitowej. Dzięki temu wymaganie pamięciowe zostało zredukowane do 10 GB pamięci \code{VRAM}, czy też \code{RAM} w przypadku braku odpowiedniej karty graficznej, lecz zwiększa to czas generowania zapytań z kilku do kilkunastu sekund.

\section{Manualna ocena}
W celu dokonania manualnej oceny modeli \code{RESDSQL} i \code{C3}, a także całej aplikacji, dokonane zostały przez autora pracy dogłębne testy. Poza tym wybrana została grupa 5 studentów, z których każdy poświęcił około 30 minut na zapoznanie się z aplikacją i wyraził na jej temat opinię. Czworo z nich studiowało nauki techniczne i znali język SQL, lecz w bardzo różnym stopniu. W badaniu uczestniczyła również studentka psychologii, która o istnieniu języka SQL nawet nie miała pojęcia. Od tych chętnych do przetestowania aplikacji osób starano się uzyskać między innymi opinię na temat wygody użytkowania oraz każdego z dostępnych modeli. Pytano również, czy znaleźliby u siebie dla niej zastosowanie i aktywnie korzystali.

\subsection{Wygoda korzystania}
Błahym problemem, który nie spotkał większości osób, były sporadyczne awarie aplikacji -- przestawała ona reagować. Każdy wykonywał testy na własnym komputerze, gdyż aplikacja została tymczasowo udostępniona w sieci i wystarczyło wejść na wskazany adres. Z pewnością pojawienie się tej niedogodności jest uwarunkowane środowiskiem, w którym aplikacja jest używana. Autorowi nie udało się niestety odtworzyć tego błędu na własnym sprzęcie, nawet korzystając z tych samych przeglądarek, co dwie osoby, które go napotkały. Tak więc problemu nie udało się pozbyć, lecz nie uznano tego za kluczowe z punktu widzenia realizowanego tematu.

Inną niedogodnością, którą każda z testujących osób w mniejszym lub większym stopniu podkreśliła, jest konieczność wprowadzania naturalnych odpowiedników dla nazw schematu. W przypadku baz danych, gdzie schemat jest w języku angielskim, nie stanowi to wielkiego problemu, ponieważ zaimplementowany mechanizm skutecznie rozdziela kilkuelementowe identyfikatory na słowa. W przypadku polskich schematów ochotnicy musieli jednak ręcznie dodawać polskie znaki, co niektórych wyraźnie frustrowało. Jest to na pewno uzasadnione, gdy rozważana aplikacja ma być rozwiązaniem inteligentnym, a zmusza użytkowników do robienia tak przyziemnych rzeczy, jak dodawanie polskich znaków. Z pewnością można w przyszłości tę część usprawnić.

\subsection{Dokładność modeli}
Żadna z osób nie miała większych problemów z zadawaniem pierwszych pytań. Często jednak były one szczegółowe, a przykładowe bazy danych nie zawierają wiele informacji, więc zapytania SQL nie zwracały żadnych rekordów. Sugerowano wówczas, aby rozpocząć od zadawania pytań bardziej ogólnych, które potem stawały się coraz bardziej skomplikowane. Na początku większość osób badała model \code{RESDSQL}, gdyż działając na \code{GPU} zwraca odpowiedzi niemal natychmiastowo. Gdy zauważyliśmy błąd w zapytaniu, to wówczas ponawiali pytanie, lecz z modelem \code{C3}, który niemal zawsze radził sobie lepiej. Ostatecznie każdy z uczestników badania wypracował sobie opinię, że model \code{C3} jest dokładniejszy. Pytani o to, czy dłuższy czas czekania im nie przeszkadza, stwierdzali, że kilkanaście sekund nie stanowi problemu. Jedna osoba zauważyła, że niemal każdy korzysta już z asystenta \code{ChatGPT} \mycite{chatgpt} i przyzwyczailiśmy się do pewnych opóźnień.

Zauważono kilka scenariuszy, w których szczególnie widać wyższość modelu \code{C3}. Jednym z nich jest pytanie o konkretne obiekty z bazy danych, gdyż \code{C3} potrafi lepiej odmieniać różne wyrażenia. Przykładowo, gdy zapytamy o wszystkie psy należące do Sary, to wysoce prawdopodobne, że \code{RESDSQL} zwróci oczywiście błędne zapytanie z fragmentem \code{WHERE imie="Sary"}, a \code{C3} zadziała poprawnie. Innym scenariuszem jest zadawanie nietypowych dla języka SQL zapytań, na przykład \enquote{Podaj dla każdego właściciela listę psów} lub \enquote{Zwróć imiona psów, które zaczynają się na tę samą literę, na którą kończy się imię właściciela}. Wymagają one znajomości funkcji \mbox{\code{group\_concat}} oraz \code{substr}, których w zbiorze treningowym \code{RESDSQL} się nie doświadczy. \code{C3} nie posiada natomiast w tej kwestii żadnych ograniczeń, ma bowiem dostęp do ogromnej wiedzy modelu \code{GPT-3.5-turbo}, trenowanego na danych z sieci.

Obserwując zadawane przez testerów pytania i zwracane przez modele odpowiedzi, zauważono, że często zapytania produkowane przez \code{RESDSQL} można uznać za poprawne, lecz nie do końca zgodne z tym, czego spodziewali się użytkownicy. Przykładowo zadając pytanie \enquote{Zwróć liczbę studentów na każdym semestrze} użytkownicy spodziewają się zobaczyć tabelę z nazwami semestrów oraz liczbą studentów na każdym z nich. W przypadku takiego zapytania model może natomiast zwrócić wyłącznie liczby studentów. Ewentualnie doda semestry, lecz w postaci ich liczbowych identyfikatorów. W pytaniu nie było określone, że te nazwy semestrów mają się pojawić. Jest to jednak wiedza domenowa, z którą model \code{C3} radzi sobie lepiej, co wykazały nawet wcześniejsze testy na zbiorze \code{Pol-Spiderdk}.

Dokładność modeli można podsumować twierdzeniem, że model \code{C3} produkuje w praktyce wyraźnie lepsze zapytania względem \code{RESDSQL}. Odbywa się to kosztem dłuższego czasu oczekiwania, lecz nie stanowi to dużego problemu. Mimo wszystko \code{C3} nie jest bezbłędny i zdarza mu się pomylić nazwy kolumn, błędnie dokonać złączenia tabel, czy niepoprawnie zrozumieć żądanie użytkownika.

\subsection{Praktyczne zastosowanie}
Większość pytanych osób stwierdziła, że mogłaby znaleźć dla stworzonego rozwiązania zastosowanie, chociażby w swojej pracy zawodowej. Uzasadniały, że modele nie zawsze produkują prawidłowe zapytania, ale ich poprawienie wymaga mniej wysiłku. Negatywną opinię wyraziła jednak osobą z najlepszą znajomością języka \code{SQL}, bo uznała, że z testowanej aplikacji by nie korzystała. Uważa ona, że więcej czasu potrzebuję na wygenerowanie i weryfikację zapytania, niż napisanie go od zera. Wskazała jednak na użyteczność dla mniej doświadczonych osób.

Konieczne jest niestety podkreślenie, że ze stworzonej aplikacji nie powinien korzystać każdy. Zaobserwowano to na przykładzie testującej aplikację osoby, która SQL nie znała. Zdarzało się, że produkowane zapytania były wykonywalne i zwracały wyniki, wydające się być poprawnymi, lecz było inaczej. Osoba ta nie mogła zweryfikować poprawności zapytania SQL, co może być wręcz niebezpieczne i prowadzić do wyciągania nieprawidłowych wniosków. Tak więc opracowane rozwiązanie nie realizuje szczytnego celu, jakim było zapewnienie każdemu łatwego dostępu do informacji, ponieważ minimalna znajomość języka SQL wciąż jest koniecznością.