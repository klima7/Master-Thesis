\section{C3}
\code{C3} jest dość nowym rozwiązaniem, które zostało opublikowane w lipcu 2023 roku w artykule pod tytułem \bibtitle{C3: Zero-shot Text-to-SQL with ChatGPT} \cite{Dong2023}. Należy ono do niedawno powstałego nurtu zaprzęgającego duże modele językowe do generowania zapytań SQL. Zapytania są kompletne, gdyż model ten przewiduje również odpowiednie wartości. Cały kod źródłowy \code{C3} został udostępniony przez autorów za pośrednictwem platformy GitHub \cite{c3-repository}. 

\subsection{Działanie}
Sposób działania \code{C3} istotnie odbiega od funkcjonowania opisywanych wcześniej rozwiązań, gdyż należy ono do zupełnie innej kategorii. Zgodnie z wprowadzonym we wcześniejszym rozdziale podziałem nie jest to model dedykowany, lecz rozwiązanie wykorzystujące duże modele językowe wraz z techniką \code{prompt engineering}. Oznacza to, że żaden trening nie jest potrzebny, a nacisk przeniesiony został na skonstruowanie wejścia do modelu \code{GPT-3.5-Turbo}, które pozwoli jak najlepiej aktywować i wykorzystać zawartą w nim wiedzę. Dane wejściowe do tego modelu mają postać konwersacji, czyli naprzemiennie występujących wiadomości od człowieka oraz od inteligentnego asystenta. Wyjściem jest natomiast wiadomość od asystenta, będąca kontynuacją ten konwersacji.

W celu przewidzenia kompletnego zapytania SQL model \code{GPT-3.5-Turbo} jest wykorzystywany trzykrotnie. W pierwszej kolejności przekazywane jest mu pytanie wraz ze schematem bazy danych i proszony jest o zwrócenie nazw tabel posortowanych względem istotności. W drugim kroku w instrukcji wejściowej przekazywane jest pytanie, cztery najistotniejsze tabele wraz z kolumnami oraz relacje między nimi i model proszony jest o posortowanie kolumn w obrębie każdej tabeli od najbardziej do najmniej istotnej. Ostatecznie do \code{GPT-3.5-Turbo} przekazywane jest pytanie, elementy schematu uznane za istotne, klucze obce oraz wartości z bazy danych znalezione w procesie \code{schema linking} i jest on proszony o wygenerowanie gotowego zapytania.

Podczas tworzenia \code{C3} wykorzystano 3 istotne techniki od których model wziął swoją nazwę. Określono jest bowiem jako \code{\underline{C}lear Prompting}, \code{\underline{C}alibration with Hints} oraz \code{\underline{C}onsistent Output}. Pierwsza z nich polega na tworzeniu instrukcji wejściowych o przejrzystym układzie i zamieszczaniu w nich jedynie elementów najważniejszych. Druga sprowadza się do obserwacji odchyleń względem oczekiwań w odpowiedziach modelu językowego i podawaniu we wcześniejszej konwersacji wskazówek, które to korygują. Ostatnia technika oznacza intensywne wykorzystanie strategii nazywanej \code{self-consistency} \cite{Wang2022}. Jest ona związana z faktem, że odpowiedzi modeli językowych nie są deterministyczne - przekazywanie tych samych informacji wejściowych zwykle skutkuje różnymi odpowiedziami. W związku z tym często dobrym pomysłem jest podanie do modelu tych samych informacji kilka razy, zebranie wszystkich odpowiedzi i wyłonienie spośród nich tej najczęstszej.

\subsection{Modyfikacje dla języka polskiego}
Z punktu widzenia przystosowania \code{C3} do języka polskiego najistotniejsza była modyfikacja promptów, czyli instrukcji wejściowych do modelu językowego. Można było dokonać tego na różne sposoby, lecz trzy z nich wydają się być najbardziej oczywiste. Pierwszym jest przetłumaczenie promptów w całości na język polski. Wymaga to jednak całkowitej ich podmiany i w związku z tym wysiłek twórców włożony w ich dopracowanie jest w dużym stopniu tracony. Poza tym modele językowe są uczone w większości na danych angielskich i dla tekstów angielskich osiągają najlepsze wyniki. Drugim z rozważanych podejść był kompletny brak tłumaczenia promptów. Nagłe pojawienie się polskiego pytania oraz polskich elementów schematu bazy danych w instrukcji wejściowej wydaje się jednak być dość nietypowe i niespodziewane, co przypuszczalnie może pogarszać wyniki. Dlatego ostatecznie zdecydowano się pozostawić prompty w języku angielskim, lecz wprowadzić kilka delikatnych modyfikacji.

\subsection{Eksperymenty}

\subsection{Wyniki}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|r|r|r|r|r|}
        \hline
        \thead{Zbiór} & \thead{Easy} & \thead{Medium} & \thead{Hard} & \thead{Extra} & \thead{Razem} \\
        \hline
        pol-spider-100 & 
        \threevals{54}{54}{83} &
        \threevals{43}{43}{91} &
        \threevals{44}{38}{44} &
        \threevals{13}{13}{75} &
        \threevals{41}{40}{79} \\
        
        pol-spider-pl-50 &
        \threevals{58}{58}{83} &
        \threevals{50}{50}{91} &
        \threevals{38}{38}{63} &
        \threevals{13}{13}{75} &
        \threevals{44}{44}{82} \\
        
        pol-spider-en-50 &
        \threevals{50}{50}{83} &
        \threevals{36}{36}{91} &
        \threevals{50}{38}{25} &
        \threevals{13}{13}{75} &
        \threevals{38}{36}{76} \\
        
        \hline
        
        pol-spidersyn-100 &
        \threevals{32}{32}{55} &
        \threevals{39}{36}{61} &
        \threevals{28}{27}{56} &
        \threevals{0}{0}{38} &
        \threevals{29}{28}{55} \\
        
        pol-spiderdk-100 &
        \threevals{100}{75}{75} &
        \threevals{50}{48}{59} &
        \threevals{36}{36}{79} &
        \threevals{15}{15}{50} &
        \threevals{51}{45}{63} \\
        
        pol-sparc-100 &
        \threevals{61}{61}{79} &
        \threevals{22}{18}{68} &
        \threevals{0}{0}{50} &
        \threevals{0}{0}{0} &
        \threevals{46}{45}{73} \\
        
        pol-cosql-100 &
        \threevals{62}{56}{87} &
        \threevals{31}{31}{77} &
        \threevals{29}{22}{36} &
        \threevals{0}{0}{50} &
        \threevals{44}{40}{74} \\
        
        \hline
    \end{tabular}
    \caption{Wyniki modelu \code{C3} na poszczególnych zbiorach. Wartości w każdej komórce posiadają format EM \slashsep{ EM with values} \slashsep{ EX}}
    \label{tab:c3sql-difficulty}
\end{table}

\subsection{Analiza}
