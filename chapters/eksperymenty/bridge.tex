\section{BRIDGE}
\code{BRIDGE} jest to rozwiązanie, które zostało opublikowane w roku 2020 przez Xi Victoria Lin, Richarda Socher oraz Caiming Xiong \cite{Lin2020}. Powstało więc nieco ponad rok po \code{RAT-SQL} i w odróżnieniu od niego generuje kompletne zapytania SQL z wartościami, co jest istotną zaletą. Jego kod źródłowy jest umieszczony na platformie Github \cite{bridge-repository}.

\subsection{Działanie}
Działanie \code{BRIDGE} znacząco odbiega od \code{RAT-SQL}. W tym przypadku wykorzystano enkodowanie oparte na serializacji informacji wejściowych do długiego tekstu i przekazaniu go do pretrenowanego modelu \code{BERT}. Dekodowanie opiera się natomiast na generowaniu słów jedno po drugim, zamiast generowania akcji tworzących drzewo \code{AST}. Na obu etapach zastosowano ciekawe techniki, które dodatkowo poprawiają skuteczność.

Enkodowanie opiera się na skonstruowaniu sekwencji tekstowej zawierającej wszystkie nazwy tabel, gdzie po każdej nazwie tabeli znajduję się lista zawartych w niej kolumn. Na początku tej sekwencji doklejane jest dodatkowo rozpatrywane pytanie. Wcześniej wykonywany jest etap \code{schema linking} w celu znalezienia połączeń typu \code{value link} i odnalezione dopasowania w zawartości bazy danych są  wstawiane po nazwie odpowiedniej kolumny. W celu zachowania znaczenia poszczególnych części stworzonej sekwencji wykorzystywane są specjalne tokeny \code{[T]}, \code{[C]} oraz \code{[V]}, które są wstawiane odpowiednio przed każdą nazwą tabeli, kolumny i wartością. Stworzony tekst jest następnie przetwarzany przez model językowy \code{BERT} i dodane po nim dwie lekkie warstwy \code{LSTM}. W ten sposób uzyskiwane są wykorzystywane przez dekoder wektorowe reprezentacje wszystkich tabel, kolumn i pytania. Reprezentacje kolumn są jednak dodatkowo wzbogacane za pomocą trenowanych równolegle wektorów reprezentujących metainformację, takie jak bycie kluczem podstawowym, bycie kluczem obcym, czy posiadanie konkretnego typu danych. Łącznie podstawowych reprezentacji z tymi metainformacjami dokonuję się prostą warstwą liniową.

Wykorzystany dekoder generuje wyjściowe zapytanie słowo po słowie. Nie jest to jednak typowy dekoder, jak te wykorzystywane w modelach językowych, ponieważ na każdym kroku dekodowania poza wyprodukowaniem jednego tokena ze słownika może dokonać także kopiowania go z pytania lub spośród nazw tabel i kolumn. Aby umożliwić takie zachowanie standardowy dekoder bazujący na \code{LSTM} został połączony z siecią typu \code{pointer network} \cite{Vinyals2015}, która potrafi wskazywać konkretne pozycje w sekwencjach wejściowych. Poza tym dekoder został nauczony w taki sposób, aby produkować zapytania w kolejności wykonywania, czyli takiej w której wykonałby je silnik bazodanowy. Powoduje to, że nazwy tabel generowane są przed nazwami kolumn i dzięki temu podczas generowania nazwy kolumny można ograniczyć się jedynie do kolumn dostępnych we wcześniej wymienionych tabelach.

\subsection{Modyfikacje dla języka polskiego}
Przystosowanie \code{BRIDGE} do języka polskiego okazało się znacznie prostsze niż to było w przypadku \code{RAT-SQL}. Tutaj również pracę rozpoczęto od uruchomienia oryginalnego rozwiązania, więc napisano plik \code{Dockerfile}, który tworzy obraz dockerowy zawierający kompletne środowisko. Jedynym problemem okazał się brak wśród zależności projektu biblioteki \code{numpy}, która była wykorzystywana. Naprawiono to poprzez dodanie odpowiedniej linii kodu.

Jedyną ważną modyfikacją dla języka polskiego, której dokonano, jest zmiana wykorzystywanego modelu \code{BERT} z wariantu \code{bert-large-uncased} na \code{bert-base-multilingual-uncased}. Zmiana ta jest bardzo podobna do tej zaaplikowanej w \code{RAT-SQL}. Uzasadnienie również jest podobne: zmieniono model na wersję wielojęzyczną, by poradziła sobie z językiem polskim oraz wykorzystano wersję mniejszą, by umożliwić naukę na posiadanym sprzęcie. 

\subsection{Eksperymenty}
W ramach eksperymentów postanowiono dokonać treningu modelu \code{BRIDGE} i go przetestować. Nauki postanowiono dokonać na zbiorze \code{pol-spider-mix}, ponieważ wcześniej przeprowadzone eksperymenty z \code{RAT-SQL} pokazały, że model nauczony na połączonym zbiorze polskim i angielskim nauczył się lepiej. Oczywiście nie można założyć na tej podstawie, że każdy jeden model uczony na połączonym zbiorze będzie skuteczniejszy. Można jednak przypuszczać, że zwykle tak jest.

Model uczono przez 36 godzin, a zaimplementowany wewnątrz procedury treningu kod dokonywał w tym czasie regularnego obliczania metryki \code{exact set match without values} na części testowej zbioru \code{pol-spider}. Wykres przedstawiający jak zmieniała się wartość tej metryki na przestrzeni czasu przedstawiono na rysunku \ref{plot:bridge-accuracy}. Na wykresie tym widać, że skuteczność modelu rosła wyraźnie przez połowę czasu treningu, a w drugiem połowie już nie widać tendencji wzrostowej - dlatego naukę postanowiono przerwać. Jako finalny został wybrany model w punkcie w którym wartość wspomnianej metryki była najwyższa.

\begin{figure}[ht!]
  \begin{center}
    \begin{tikzpicture}
      \begin{axis}[
        width=\linewidth,
        height=\fpeval{0.5*\linewidth},
        xmin=0, xmax=37,
        grid=major,
        xlabel={Czas treningu [godziny]},
        ylabel=EM without values,
      ]
        \addplot table[x=time,y=dev_exact_match,col sep=comma] {plots/bridge_training.csv}; 
      \end{axis}
    \end{tikzpicture}
    \caption{Wyniki metryki \code{EM} na części testowej zbioru \code{pol-spider} w czasie trwania treningu modelu}
    \label{plot:bridge-accuracy}
  \end{center}
\end{figure}

\subsection{Wyniki}
Wyniki przeprowadzonego eksperymentu przedstawiono w tabeli \ref{tab:bridge-difficulty}. Jest ona znacznie bardziej rozbudowana niż to było w przypadku rozwiązania \code{RAT-SQL}, ponieważ ten model zwraca zapytania z wartościami. Możliwe więc stało się obliczenie metryk \code{EM with values} oraz \code{EX}.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|r|r|r|r|r|}
        \hline
        \thead{Zbiór} & \thead{Easy} & \thead{Medium} & \thead{Hard} & \thead{Extra} & \thead{Razem} \\
        \hline
        pol-spider & 
        \threevals{79,4}{71,2}{82,9} &
        \threevals{59,8}{51,9}{68,9} &
        \threevals{43,1}{40,2}{63,8} &
        \threevals{34,6}{31,9}{54,5} &
        \threevals{57,6}{51,4}{69,1} \\
        
        pol-spider-pl &
        \threevals{80,6}{72,6}{84,3} &
        \threevals{60,3}{52,5}{70,0} &
        \threevals{44,8}{40,2}{64,9} &
        \threevals{34,9}{31,3}{53,6} &
        \threevals{58,5}{51,8}{69,9} \\
        
        pol-spider-en &
        \threevals{78,2}{69,8}{81,5} &
        \threevals{59,2}{51,3}{67,9} &
        \threevals{41,4}{40,2}{62,6} &
        \threevals{34,3}{32,5}{55,4} &
        \threevals{56,8}{50,9}{68,3} \\
        
        en-spider &
        \threevals{86,7}{82,3}{85,1} &
        \threevals{67,9}{62,8}{71,7} &
        \threevals{51,7}{48,3}{58,0} &
        \threevals{40,4}{38,0}{43,4} &
        \threevals{65,3}{61,0}{68,1} \\
        
        \hline
        
        pol-spidersyn &
        \threevals{63,2}{56,1}{71,6} &
        \threevals{48,3}{41,7}{59,3} &
        \threevals{37,1}{36,4}{52,6} &
        \threevals{23,1}{21,5}{43,8} &
        \threevals{45,7}{40,8}{58,4} \\
        
        pol-spiderdk &
        \threevals{58,6}{51,4}{63,6} &
        \threevals{39,4}{32,9}{49,4} &
        \threevals{22,3}{22,3}{44,6} &
        \threevals{15,7}{13,8}{31,9} &
        \threevals{36,4}{31,5}{48,2} \\
        
        pol-sparc &
        \threevals{61,7}{60,0}{68,1} &
        \threevals{38,8}{44,1}{60,2} &
        \threevals{\s3,3}{25,0}{43,3} &
        \threevals{25,0}{17,6}{43,8} &
        \threevals{52,0}{47,6}{64,3} \\
        
        pol-cosql &
        \threevals{60,0}{52,5}{69,2} &
        \threevals{44,1}{34,7}{63,6} &
        \threevals{25,0}{19,1}{54,4} &
        \threevals{17,6}{14,7}{47,1} &
        \threevals{47,6}{40,2}{63,9} \\
        
        \hline
    \end{tabular}
    \caption{Wyniki modelu \code{BRIDGE} na poszczególnych zbiorach. Wartości w każdej komórce posiadają format EM \slashsep{ EM with values} \slashsep{ EX}}
    \label{tab:bridge-difficulty}
\end{table}

\subsection{Analiza}
Zestawiając ze sobą wyniki osiągnięte metodą \code{BRIDGE} oraz \code{RAT-SQL} trudno jest wskazać pod względem metryki \code{EM without values} model lepszy. Na częściach testowych wszystkich wariantów zbioru \code{Spider} analizowany teraz model \code{BRIDGE} okazuję się działać lepiej. Na zbiorach pokrewnych \code{pol-spiderdk}, \code{pol-sparc} oraz \code{pol-cosql} jednak to \code{RAT-SQL} jest skuteczniejszy. Można z tego wyciągnąć wniosek, że \code{BRIDGE} sprawdza się lepiej, jeżeli trenowany i testowany jest na podobnych danych. \code{RAT-SQL} wydaje się natomiast posiadać bardziej rozwiniętą umiejętność generalizacji i wykorzystania wiedzy domenowej, przez co osiąga lepsze wyniki na zbiorach wyraźnie odbiegających od treningowego. 

Metoda \code{BRIDGE} nie jest już tak popularna w literaturze jak \code{RAT-SQL} i eksperymenty z jej wykorzystaniem przeprowadzili jedynie autorzy rosyjskiego tłumaczenia zbioru \code{Spider}, czyli autorzy zbioru \code{PAUQ}. Zestawienie osiągniętych przez nich wyników z niniejszymi przedstawiono w tabeli \ref{tab:bridge-translations-results}. Widać, że zgodnie z metryką \code{EM} na zbiorze polskim udało się osiągnąć wyniki nieco lepsze. Jednym z możliwych powodów jest przypuszczalnie wyższy stopień skomplikowania języka rosyjskiego. Różnica w wynikach metryki \code{EX} jest natomiast znacznie większa i co zaskakujące, dla odmiany na korzyść zbioru rosyjskiego. Przyczyną tego jest pewne zakłamanie metryki \code{EX} dla języka polskiego, o czym wcześniej wspomniano. W pełni uzasadnione jej zaaplikowanie wymagałoby bowiem przetłumaczenia zawartości wszystkich baz danych, czego dla polskiego zbioru nie zrobiono, a w przypadku zbioru rosyjskiego zostało to dokonane częściowo. Generalnie przedstawione zestawienie stanowi potwierdzenie tego, że modyfikacji metody \code{BRIDGE} dla języka polskiego dokonano poprawnie.

\begin{table}[ht!]
    \centering
    \begin{tabular}{|c|r|r|}
        \hline
        \multirow{2}{*}[-0.8em]{\thead{Tłumaczenie \\zbioru Spider}} & \multicolumn{2}{c|}{\thead{Zbiór treningowy}} \\
        \cline{2-3}
        \multirow{2}{*}{} & \thead{Tłumaczenie} & \thead{Tłumaczenie\\ + angielski} \\
        \hline
        \multicolumn{1}{|l|}{Rosyjskie (\code{PAUQ})} & \twovals{52,0}{48,0} & \twovals{55,0}{50,0} \\
        \multicolumn{1}{|l|}{Polskie (\code{Pol-Spider})} & \twovals{---}{---} & \twovals{57,6}{69,1} \\
        \hline
    \end{tabular}
    \caption{Zestawienie wyników osiągniętych przez model \code{BRIDGE} dla różnych tłumaczeń zbioru \code{Spider} i zbiorów treningowych}
    \label{tab:bridge-translations-results}
\end{table}

Analizując dalej tabelę \ref{tab:bridge-difficulty} można zauważyć, że wyniki metryki \code{EM with values} są mniejsze od \code{EM without values}, co jest oczywiście spodziewane i zawsze tak być powinno. Różnica pomiędzy nimi wynosi średnio 5,6 punktów procentowych, co oznacza, że ponad pięć procent generowanych zapytań jest poprawnych pod względem struktury, lecz posiada błąd w przewidzianych wartościach. Widać więc, że generowanie wartości stanowi istotne wyzwanie. Dla \code{RESDSQL} aktualne są również spostrzeżenia poczynione dla poprzedniego modelu, takie jak spadek skuteczności wraz ze wzrostem poziomu trudności, czy niższa dokładność w przypadku zbiorów pokrewnych.

